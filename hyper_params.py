import logging
import numpy as np

SEED = 0
OUTPUT_DIR = "./out"

TENSORFLOW_GPU_COUNT = 1
TENSORFLOW_CPU_COUNT = 4
TENSORFLOW_GPU_MEM_ALLOC_FRACT = 0.35

LOG_LEVEL = logging.INFO
NUM_GAMES = 128
NUM_TRAIN_LOOP_ITER = 400
NUM_ITER = 10
NUM_WORKERS = 8
BATCH_SIZE = 128
PREDICTION_QUEUE_BATCH_SIZE = 4
STATE_HIST_SIZE = 8
NUM_EVAL_GAMES = 9
MIN_MODEL_REPLACEMENT_WIN_RATIO = 0.55 # 55%
MCTS_STEPS = 100
MAX_GAMES_HISTORY_SIZE = 20000
MODEL_FILE = "%s/model-ago-7x7x100-12022334-2-56.h5" % OUTPUT_DIR

PLAYER_1 = 0
PLAYER_2 = 1
EPS = 1e-8

REWARD_DRAW = -1.0
REWARD_WIN = 1.0
REWARD_LOOSE = -1.0
OUTCOME_DRAW = 0
OUTCOME_WIN_PLAYER_1 = 1
OUTCOME_WIN_PLAYER_2 = 2
BOARD_SIZE = 7
ZERO_TEMP_MOVE_INDEX = 15
TEMPERATURES = [(0, ZERO_TEMP_MOVE_INDEX, 1.0), (ZERO_TEMP_MOVE_INDEX, np.inf, 1e-8)]
TEMPERATURE_MIN = 1e-3

ACTION_SPACE_SIZE = BOARD_SIZE*BOARD_SIZE+1
DIRICHLET_ALPHA = 0.03
ACT_NOISE_EPS = 0.25
C_PUCT = 1.0

CONV_FILTERS = 32
CONV_KERNEL = (3, 3)
NUM_RESIDUAL_BLOCKS = 4
DENSE_SIZE = 32


# # small board, fast training - debug:
# LOG_LEVEL = logging.INFO
# NUM_GAMES = 16
# NUM_TRAIN_LOOP_ITER = 200
# NUM_ITER = 3
# NUM_WORKERS = 8
# BATCH_SIZE = 128
# PREDICTION_QUEUE_BATCH_SIZE = 4
# STATE_HIST_SIZE = 8
# NUM_EVAL_GAMES = 5
# MIN_MODEL_REPLACEMENT_WIN_RATIO = 0.55 # 55%
# MCTS_STEPS = 15
# MAX_GAMES_HISTORY_SIZE = 20000

# PLAYER_1 = 0
# PLAYER_2 = 1
# EPS = 1e-7

# REWARD_DRAW = -1.0
# REWARD_WIN = 1.0
# REWARD_LOOSE = -1.0
# OUTCOME_DRAW = 0
# OUTCOME_WIN_PLAYER_1 = 1
# OUTCOME_WIN_PLAYER_2 = 2
# BOARD_SIZE = 5
# ZERO_TEMP_MOVE_INDEX = 15
# TEMPERATURES = [(0, ZERO_TEMP_MOVE_INDEX, 1.0), (ZERO_TEMP_MOVE_INDEX, np.inf, 1e-8)]
# TEMPERATURE_MIN = 1e-3

# ACTION_SPACE_SIZE = BOARD_SIZE*BOARD_SIZE+1
# DIRICHLET_ALPHA = 0.03
# ACT_NOISE_EPS = 0.25
# C_PUCT = 1.0

# CONV_FILTERS = 16
# CONV_KERNEL = (3, 3)
# NUM_RESIDUAL_BLOCKS = 2
# DENSE_SIZE = 16


